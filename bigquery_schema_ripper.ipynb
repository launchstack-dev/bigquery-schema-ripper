{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B9sVaUKQnjx"
      },
      "outputs": [],
      "source": [
        "# üõ†Ô∏è Step 1: Authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# üì¶ Imports\n",
        "from google.cloud import bigquery\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# üß† Step 2: Set project ID\n",
        "PROJECT_ID = 'INSERT_BIGQUERY_PROJECT_ID_HERE'  # Replace with your actual project\n",
        "\n",
        "# üí¨ Step 3: Optional dataset selector\n",
        "dataset_input = input(\"Enter a specific Dataset ID to scan (or leave blank to scan ALL datasets): \")\n",
        "target_dataset_id = dataset_input.strip()\n",
        "\n",
        "# üí¨ Step 4: Choose export format\n",
        "export_format_input = input(\"Choose export format ('csv' or 'json'): \")\n",
        "export_format = export_format_input.strip().lower()\n",
        "assert export_format in ['csv', 'json'], \"Please enter 'csv' or 'json'\"\n",
        "\n",
        "# üîå Step 5: Initialize client\n",
        "creds, _ = default()\n",
        "client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
        "\n",
        "# üì° Step 6: Extract schema\n",
        "print(f\"\\nüîç Scanning BigQuery project: {PROJECT_ID}\")\n",
        "schema_data = []\n",
        "\n",
        "datasets = client.list_datasets()\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_id = dataset.dataset_id\n",
        "    full_dataset = f\"{PROJECT_ID}.{dataset_id}\"\n",
        "\n",
        "    if target_dataset_id and dataset_id != target_dataset_id:\n",
        "        continue  # Skip unrelated datasets if one is specified\n",
        "\n",
        "    print(f\"\\nüìÅ Dataset: {full_dataset}\")\n",
        "    tables = client.list_tables(full_dataset)\n",
        "\n",
        "    if not tables:\n",
        "        print(\"  (No tables found)\")\n",
        "        continue\n",
        "\n",
        "    for table in tables:\n",
        "        full_table_id = f\"{full_dataset}.{table.table_id}\"\n",
        "        print(f\"  üìÑ Table: {table.table_id}\")\n",
        "        table_ref = client.get_table(full_table_id)\n",
        "\n",
        "        for field in table_ref.schema:\n",
        "            schema_entry = {\n",
        "                \"project_id\": PROJECT_ID,\n",
        "                \"dataset_id\": dataset_id,\n",
        "                \"table_id\": table.table_id,\n",
        "                \"field_name\": field.name,\n",
        "                \"field_type\": field.field_type,\n",
        "                \"field_mode\": field.mode\n",
        "            }\n",
        "            schema_data.append(schema_entry)\n",
        "            print(f\"    - {field.name} ({field.field_type}, {field.mode})\")\n",
        "\n",
        "# üíæ Step 7: Export schema\n",
        "df = pd.DataFrame(schema_data)\n",
        "filename = f\"bigquery_schema.{export_format}\"\n",
        "filepath = f\"/content/{filename}\"\n",
        "\n",
        "if export_format == \"csv\":\n",
        "    df.to_csv(filepath, index=False)\n",
        "elif export_format == \"json\":\n",
        "    with open(filepath, \"w\") as f:\n",
        "        json.dump(schema_data, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Schema exported to '{filename}'\")\n",
        "\n",
        "# üì§ Step 8: Choose destination\n",
        "destination_input = input(\"Do you want to save to Google Drive? (yes/no): \").strip().lower()\n",
        "\n",
        "if destination_input == \"yes\":\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_path = f\"/content/drive/My Drive/{filename}\"\n",
        "        os.rename(filepath, drive_path)\n",
        "        print(f\"‚úÖ File saved to Google Drive at: {drive_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to save to Drive: {e}\")\n",
        "else:\n",
        "    from google.colab import files\n",
        "    files.download(filepath)\n",
        "    print(\"üìé File download initiated.\")\n"
      ]
    }
  ]
}